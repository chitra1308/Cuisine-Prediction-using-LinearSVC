{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "##nesscity librares\n",
    "#pandas used for data frame\n",
    "import pandas as pd \n",
    "#numpy used for all math function\n",
    "import numpy as np\n",
    "#matplotlib sun fn of pyplot used for viusalize data in graphic\n",
    "import matplotlib.pyplot as py\n",
    "#For ML Purpose used libraises\n",
    "#Cross_val to calculate the value of model\n",
    "#kfold it used for how many times your test and train  data want to split. Each time it will give different of dataset based on kfold\n",
    "#kfold Ex: a=[1,2,3,4,5,6] kfold=3 --> the 'a' dataset should be change follow upk[n-1]:k=3 a=[1,4,5,6,2,3] ,k=2 a=[6,5,4,3,2,1], k=1 a[3,2,1,6,4,5]\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "#the model used for calculated the accuracy_score of the mode . For this we should give a parameter of 'X[independent],Y[Depent]'\n",
    "from sklearn.metrics import accuracy_score\n",
    "#This model i used to create predict model of the project\n",
    "#why i was used to project, the accuracy score is high compare to other model\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "#Term-Frequency Inverse Term Frequency[TFIDF],we can use counter vectorizer also but compare to other it was more efficient way to vectrozier of caterforical variable\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with help pandas module we can read the json file \n",
    "train=pd.read_json('train.json')\n",
    "test=pd.read_json(\"test.json\")\n",
    "\n",
    "#successfully read the json file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total row& coloumn of dataframe (39774, 3)\n",
      "             NULL  Percent\n",
      "cuisine         0      0.0\n",
      "id              0      0.0\n",
      "ingredients     0      0.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-af7ab7c614e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "#Explority Data Analysis\n",
    "#check is there any values are availabe in our data set\n",
    "#cort_values fn used to asc our values form lower to higher\n",
    "traisnull=train.isnull().sum().sort_values(ascending=True)\n",
    "#Percent=n/N*100 like wise we used in here\n",
    "trapercent=(train.isnull().sum()/train.isnull().count()*100).sort_values(ascending=True)\n",
    "#shape is usually represent the number of records had it in Json file as a coloum,row wise\n",
    "print('The Total row& coloumn of dataframe',train.shape)\n",
    "#concat fn is available in pandas lib. It's used for merge with data. axis = 0 represent for Row value vice versa axis=1 represent of column \n",
    "both=pd.concat([traisnull,trapercent],axis=1,keys=['NULL','Percent'])\n",
    "#understading purpose i used it print\n",
    "print(both)\n",
    "\n",
    "#here, we can see, we dont have that much numm values, if it we have to handle this missing values with help of Imputer fn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                id  ingredients\n",
      "cuisine                        \n",
      "italian       7838         7838\n",
      "mexican       6438         6438\n",
      "southern_us   4320         4320\n",
      "indian        3003         3003\n",
      "chinese       2673         2673\n",
      "french        2646         2646\n",
      "cajun_creole  1546         1546\n",
      "thai          1539         1539\n",
      "japanese      1423         1423\n",
      "greek         1175         1175\n",
      "spanish        989          989\n",
      "korean         830          830\n",
      "vietnamese     825          825\n",
      "moroccan       821          821\n",
      "british        804          804\n",
      "filipino       755          755\n",
      "irish          667          667\n",
      "jamaican       526          526\n",
      "russian        489          489\n",
      "brazilian      467          467\n"
     ]
    }
   ],
   "source": [
    "#this is used to view the number of cuisine in this dataset. \n",
    "#whereever we are using groupby fn at time we did used sort_values fn , ought to give 'by' parameter.\n",
    "group=train.groupby('cuisine').count().sort_values(by='id', ascending=False)\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above used to view the data raw\n",
    "#here it funtime\n",
    "# Graphic view of data\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode,iplot\n",
    "#with help of groupby fn we came to know count of cuisine. so we have create 20 colour theme \n",
    "color_theme=dict(color=['rgba(221,160,221,1)','rgba(169,169,169,1)','rgba(255,160,122,1)','rgba(176,224,230,1)','rgba(169,169,169,1)','rgba(255,160,122,1)','rgba(176,224,230,1)',\n",
    "                   'rgba(188,143,143,1)','rgba(221,160,221,1)','rgba(169,169,169,1)','rgba(255,160,122,1)','rgba(176,224,230,1)','rgba(189,183,107,1)','rgba(188,143,143,1)','rgba(221,160,221,1)','rgba(169,169,169,1)','rgba(255,160,122,1)','rgba(176,224,230,1)','rgba(169,169,169,1)','rgba(255,160,122,1)'])\n",
    "#it count the particular cuisine of ingredients. Ex: 'Cuisine': british        value_count:804 \n",
    "obj=train['cuisine'].value_counts()\n",
    "\n",
    "#This is 2D of Graph, we need x and y co-oridinate. Orientation= h represent of 'horizontal' \n",
    "#marker= her e we used to our dict values of color_theme\n",
    "\n",
    "template =go.Bar(y=obj.index[::-1],x=(obj)[::-1],orientation='h',marker=color_theme)\n",
    "\n",
    "#layout is used for border of our graph. usually title, margin,fontsize values we assign with help of graph_objs module\n",
    "\n",
    "layout=go.Layout(title='Grapics verision of cuisine',xaxis=dict(title='count of ingridents',tickfont=dict(size=14,)),\n",
    "                yaxis=dict(title='List of orgin',titlefont=dict(size=16),tickfont=dict(size=14)),margin=dict(l=200,))\n",
    "data=[template]\n",
    "figure=go.Figure(data=data,layout=layout)\n",
    "iplot(figure,filename='basic-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# used to read  json without help of pandas\n",
    "#defentiely it will make curisoity \n",
    "# call the module of Json in  python \n",
    "import json\n",
    "# define the fn name\n",
    "def read_json(path):\n",
    "    #return my caller open the specified path\n",
    "    return json.load(open(path))\n",
    "#call the  fn and create the object too\n",
    "train=read_json('train.json')\n",
    "test=read_json('test.json')\n",
    "#have data with out dataframe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate ingredients from the test and train with the help of iteration \n",
    "def create_text(data):\n",
    "    #might be non-numberic data data value lower and uppder case. for normalize purpose used to lower()\n",
    "    actualdata=(''.join(doc['ingredients']).lower() for doc in data)\n",
    "    return actualdata\n",
    "utrain=create_text(train)\n",
    "utest=create_text(test)\n",
    "#both utrain(u represent of update),utest having an ingredients values\n",
    "#Independent variable ready to proceed into model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target(depent variable) from the test and train with the help of iteration \n",
    "target= [doc['cuisine']for doc in train]\n",
    "#crate an object for Tfidfvectorizer. We should to vectorizer because we have data of text values.Machine can understand of numberice varibale\n",
    "#which is can used to text to numberic value[Tfidf]\n",
    "tfidf=TfidfVectorizer(binary=True)\n",
    "\n",
    "#X[indepent],y[depent] are serve to ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the tf-idf which used to change out string values into machine understand values of numeric\n",
    "def final(obj,identify):\n",
    "    if identify=='train':\n",
    "        #fit_transform and transform is used for nomalize your data in a particular range\n",
    "        #we have formual for z score=x-(mu)/sigma [normalize]\n",
    "        #the above formula give your data on a particular range\n",
    "        #fit(): is used to calculate of parameterof  mu and sigma value of your train data and save it in a internal objects\n",
    "        #transform: is used for the above calculated parameter we can transform for an particular dataset\n",
    "        #fit_transform: calculate the parameters and trasformer to the train dataset\n",
    "        Pred=tfidf.fit_transform(obj)\n",
    "        \n",
    "    else:\n",
    "        #transform(): is used for the calculate the paramters transformed in to test dataset.\n",
    "        Pred=tfidf.transform(obj)\n",
    "    return Pred\n",
    "Train=final(utrain,'train')\n",
    "Test=final(utest,'test')\n",
    "\n",
    "#All  str values converted into numberic values\n",
    "#tf-idf: ex: n=['tea','mango','apple','orange','tea']\n",
    "#tf-idf formual: TF= number of term present in 'n'/Total number of n --> tea[TF]=2/5=0.4\n",
    "                #IDF= log(Total number of n/Number of term present in 'n') -->tea[IDF]= log(5/2)= log(2.5)=0.40\n",
    "                #so Tea if- idf value is =TF*IDF=0.4*0.40=0.16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model Preparation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#using label encoder give a weightage of target variable\n",
    "#create an object of LabelEncoder\n",
    "\n",
    "lb=LabelEncoder()\n",
    "Target=lb.fit_transform(target)\n",
    "\n",
    "\n",
    "#Target variable ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Linear SVC Result is  0.6254084603867917 0.004007452261871983\n"
     ]
    }
   ],
   "source": [
    "#used in LinearSVC \n",
    "#SVC kernal of linear is used to fit to the date provide to 'bestfit' into your model,that divide categorizes,after getting the hyperplane.\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "#create an object for linearsvc\n",
    "lc=LinearSVC()\n",
    "perfect=lc.fit(Train,Target)\n",
    "#the above steps used to check my accuracy value\n",
    "#accuracy value: how much of my predict data similar to the actual data\n",
    "#here my kfold value id 10 is will be reduce like k(n-1) that's mean k(10-1)\n",
    "kflod= model_selection.KFold(n_splits=10,random_state=7)\n",
    "Acc_results = model_selection.cross_val_score(LinearSVC(),Train,Target,cv=kflod,scoring='accuracy')\n",
    "print('The Linear SVC Result is ',Acc_results.mean(),Acc_results.std())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#Our ML model used for Test data\n",
    "#in Test data we have, calculate the paramters transformed\n",
    "\n",
    "y_test=lc.predict(Test)\n",
    "y_pred=lb.inverse_transform(y_test)\n",
    "#test data have the whole dataset, in that we are extracting the id column\n",
    "Test_Pre=[doc['id'] for doc in test]\n",
    "Res=pd.DataFrame({'id':Test_Pre,'cuisine':y_pred},columns=['id','cuisine'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id       cuisine\n",
      "0     18009      japanese\n",
      "1     28583   southern_us\n",
      "2     41580       italian\n",
      "3     29752  cajun_creole\n",
      "4     35687       italian\n",
      "5     38527        french\n",
      "6     19666       italian\n",
      "7     41217       chinese\n",
      "8     28753       mexican\n",
      "9     22659       british\n",
      "10    21749       italian\n",
      "11    44967         greek\n",
      "12    42969        indian\n",
      "13    44883       italian\n",
      "14    20827   southern_us\n",
      "15    23196       mexican\n",
      "16    35387   southern_us\n",
      "17    33780        french\n",
      "18    19001       mexican\n",
      "19    16526       mexican\n",
      "20    42455      japanese\n",
      "21    47453  cajun_creole\n",
      "22    42478   southern_us\n",
      "23    11885    vietnamese\n",
      "24    16585       italian\n",
      "25    29639   southern_us\n",
      "26    26245          thai\n",
      "27    38516       chinese\n",
      "28    47520       italian\n",
      "29    26212   southern_us\n",
      "...     ...           ...\n",
      "9914  49157    vietnamese\n",
      "9915  40847       italian\n",
      "9916  14084   southern_us\n",
      "9917   6802       italian\n",
      "9918  22381       mexican\n",
      "9919  21016       mexican\n",
      "9920  29024       italian\n",
      "9921   4478          thai\n",
      "9922  36711        indian\n",
      "9923   8300       italian\n",
      "9924  47035       italian\n",
      "9925  15596        french\n",
      "9926  19902   southern_us\n",
      "9927  31242   southern_us\n",
      "9928  21117        indian\n",
      "9929  15234  cajun_creole\n",
      "9930  24993       italian\n",
      "9931  31007       spanish\n",
      "9932  31687       mexican\n",
      "9933  13657       chinese\n",
      "9934  36612   southern_us\n",
      "9935  14008      japanese\n",
      "9936  32124        french\n",
      "9937  43570       chinese\n",
      "9938  14059        indian\n",
      "9939  30246        french\n",
      "9940  36028       mexican\n",
      "9941  22339       italian\n",
      "9942  42525   southern_us\n",
      "9943   1443       mexican\n",
      "\n",
      "[9944 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Here is the climax of the test data prediction and result of accuracy\n",
    "Acc_results1 = model_selection.cross_val_score(LinearSVC(),Test,y_pred,cv=kflod,scoring='accuracy')\n",
    "print('The Linear SVC Result of Prediction ',Acc_results1.mean(),Acc_results1.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Linear SVC Result of Prediction  0.7228474363770563 0.012963908565603843\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
